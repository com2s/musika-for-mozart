conda activate musika

cd C:\Users\genmg2\Desktop\musika-piano

python app.py --base_channels 256

---
# 소개

## 목적

우리는 Musika를 사용하여 더 나은 피아노 음악을 생성하는 모델을 만들고자 한다.

## 데이터셋

Musika에 다양한 데이터셋들을 학습시켜 보았으며 어떤 데이터셋을 사용하는가가 모델에 매우 큰 영향을 끼친다는 사실을 알 수 있었다.

일반적인 악기들의 연주, 피아노 연주(유튜브 크롤링), 클래식 피아노 연주, 피아노 midi, 드럼 midi 등을 사용해보았으며 제각기 다른 결과를 가져왔다.

## 파라미터의 수

그 외에는 모델의 생성자와 판별자가 가지는 파라미터의 수(base_channels 값)이 클수록 생성되는 음악도 더 나아졌다. 하지만 이것은 1에폭 당 걸리는 시간을 비례하여 증가시켰다. 기본값인 128일 때에는 250에폭의 학습에 약 60시간 가량이 필요했지만 2배인 256일 때에는 120시간 가량이 필요했다. 일반적으로 학습 횟수를 늘리는 것보다 이 값을 늘리는 것이 더 나은 결과를 보였다.

## 학습률 

학습률에 대해서는 일정 크기보다 커지면 모델의 학습이 제대로 이루어지지 않게 되어 비프음만 생성하는 문제가 있었다. 따라서 우리는 평소에 lr=0.00004 라는 작은 값을 사용했다. 그런데 base_channels 의 크기를 늘리면 사용해야하는 학습률도 더 작아졌기 때문에 256으로 두었을 때는 lr=0.00002 정도의 값을 썼다.

---
## 실험

여러 조건에 따른 모델 학습을 보기 위해 다수의 실험을 진행했으며 그 내용과 결과는 다음과 같다.

### 첫 번째, 두 번째 실험

처음에는 몇 개의 악기로 연주된 평범한 음악 26개 사용하고 학습률은 0.0001 로 두었다.

25에폭이 넘어가자 loss 값들이 nan으로 표기되며 샘플이 고주파음, 무음 같은 무의미한 소리로만 생성되는 문제가 발생했다. 오류가 나지 않은 체크포인트에서 음악을 생성해도 너무 학습 초기에 에러가 발생하여 원하는 수준의 생성물을 얻을 수 없었다.

두 번째 실험에서는 동일한 학습률에 서로 비슷한 60개 정도의 음악을 사용했으나 처음과 동일한 문제가 발생했다.

이 때 우리는 학습률이 크기 때문에 문제가 발생했다고 판단하고 이후에는 이 값을 낮춰서 두기로 결정했다.

### 세 번째, 네 번째 실험

세 번째 실험을 시작하기 전에 마침 오디오 관련 프로젝트를 진행한 다른 팀의 세미나를 들을 수 있고 그 분들을 통해 midi 형식의 데이터셋을 얻을 수 있었다. 이 데이터셋은 기본적으로 음질이 좋고 코드진행이 잘 구성되어있는 짧은 피아노 음원이었다. 또한 그 수가 매우 많아서 학습에 사용하기에 아주 좋았다. 여기에 학습률을 0.00002, 0.00004 로 두어 2회 각각 진행했다.

그 결과 250에폭의 학습이 두 번 모두 오류없이 잘 이루어졌다. 그러나 모델의 생성 샘플의 소리 크기가 불안정한 경우가 종종 있었다. 우리는 그 원인이 사용한 데이터셋의 볼륨이 각 파일에 따라 편차가 크기 때문으로 추측했다.

네 번째 실험에서는 앞에서 사용한 데이터셋의 볼륨에 평준화 기법을 적용하여 학습률 0.00004 로 진행했다.

앞에서 본 볼륨 문제는 해결되었고 피아노의 소리를 매우 잘 나타내고 있었지만 멜로디와 음이 너무 단순하다는 문제가 존재했다.

### 다섯 번째 실험

우리는 이 때 Musika 를 통해 두 데이터셋의 특징을 따로 학습함으로써 합칠 수 있는지에 대해 알아보고자 했다. 우리에게 피아노 midi 데이터셋과 드럼 midi 데이터셋이 있었는데 만약 이것들을 한 Musika 모델에 학습시킬 경우 드럼과 피아노 소리가 모두 혼재해 있는 결과물을 만들 수 있는가하는 것이다.

그래서 네 번째 실험으로 얻은 모델에 드럼 midi 데이터셋을 추가로 학습시켜보았는데 학습률과 에폭에 관계없이 바로 피아노의 소리는 사라지고 이후에 들어간 드럼만이 남게 되었다.

그 원인은 Musika 가 데이터를 학습하는 방식에 있는데 바로 GAN을 사용한다는 점이다. GAN은 생성자와 판별자를 동시에 학습시키는데 아무리 이전에 피아노 소리를 학습시켰어도 이후에 드럼 소리만으로 추가 학습이 진행되면 그 내부의 생성자는 드럼 소리를 만들 수밖에 없는 것이다. 따라서 이 때 피아노의 특징은 모두 사라지고 드럼의 특징만이 모델에 학습된다.

만약 파인튜닝을 원한다면 이번처럼 서로 다른 악기를 사용하는 완전히 다른 소리가 아닌 서로 대부분의 특징이 비슷하면서 아주 조금만 다른 데이터셋을 써야할 것이다.

### 일곱 번째 실험

* 여섯 번째 실험은 Jukebox 모델이 사용되어 이곳에서는 생략한다.

이 때는 드럼 midi 데이터셋만을 가지고 학습을 진행했다. 드럼은 멜로디 요소가 없지만 데이터셋에 다양한 드럼의 소리가 포함되어 있어 마치 여러 악기의 음색을 구분해 표현해야하는 것과 비슷한 일을 요구한다.

227에폭 이후 샘플을 생성해보니 박자의 유지를 어려워한다는 것을 알 수 있었다. 1분 58초 길이의 오디오를 만드는데 중간중간 박자가 틀어지는 것이 느껴졌다. 드럼이기 때문에 크게 드러나지는 않았지만 이는 아마도 모델의 멜로디 생성 능력이 부족하는 문제와 연관이 있어보였다.

하지만 드럼의 다양한 음색을 재현하는 데에는 꽤나 성공적이었고 이는 여러 악기로 연주되는 보통의 음악에 대해서도 소리를 잘 만들어낼 것이라고 생각할 수 있다.

### 여덟 번째 실험

피아노 midi 데이터셋은 깔끔한 피아노 소리를 내는 것에 성공했으나 너무 단조로운 소리만을 만드는 문제가 있었다. 그래서 우리는 실제 피아노 연주를 학습시키고자 했다. 유튜브의 1시간 이상 길이의 피아노 연주곡 모음들을 크롤링하여 사용했다.

이를 통해 멜로디는 이전보다 다양해졌으나 음질과 음색이 매우 열화되는 문제가 생기고 말았다. 크롤링 시 많은 데이터를 효율적으로 다운로드 하기 위해 1시간 이상의 긴 모음집을 사용한 것이 그 원인으로 보인다. Musika는 음원을 인코딩할 때 제한된 공간인 잠재 공간의 벡터로 오디오 파일을 압축하는 과정을 거친다. 이 때 너무 긴 음원은 압축 시 손실이 발생하는 것으로 보인다. 이는 따로 다시 디코딩하여 다른 파일과 비교해보았을 때 확실히 그 차이를 들을 수 있었다.

따라서 짧은 곡들을 다량으로 모으는 편이 데이터셋 구성에는 더 좋겠지만 그 만큼 시간 소요가 크다. 그렇기 때문에 우리는 이 문제를 해결하기 위한 3가지 방안을 생각하고 이후 실험에 적용하였다.

### 아홉 번째 실험

우선 앞서 실시한 여덟 번째 실험에서는 유튜브 크롤링으로 얻은 데이터셋을 처음부터 모델에 학습시켰었다. 그러나 이번에는 네 번째 실험에서 깔끔한 소리를 보여준 피아노 midi 데이터셋으로 학습시킨 모델을 사용하기로 했다. 이 모델은 피아노 음색을 아주 잘 보여주므로 여기에 멜로디가 다양한 데이터를 파인튜닝하고자 한 것이다.

아홉 번째 실험과 열 번째 실험에서는 파인튜닝이 아닌 여덟 번째 실험처럼 유튜브 크롤링 데이터셋만을 사용하되 클래식 음악 데이터도 추가하여 학습시켰다. 

lr=0.00004 로 15에폭 학습 후 lr=0.00001로 135에폭을 학습시키는 것으로 파인튜닝했다.

이렇게하자 midi 데이터만으로 학습시켰을 때보다 음질과 음색은 다소 떨어졌으나 여덟 번째 실험보다는 훨씬 나아졌으며 멜로디적인 부분에서의 문제도 거의 느끼지 못 했다.

우리는 지금까지 기본값으로 주어진 250에폭 정도만을 학습시켰는데 이 파인튜닝은 그것보다도 더 많은 학습을 하기 때문에 (기존의 250에폭에 파인튜닝만큼 추가로 학습하므로) 더 나아진 모습을 보여준 것이 아닌가 싶기도 하다.

### 열 번째 실험

이전에 언급했듯 열 번째 실험에서는 파인튜닝이 아닌 여덟 번째 실험처럼 유튜브 크롤링 데이터셋만을 사용하되 클래식 음악 데이터도 추가하여 학습시켰다. 그리고 두 가지 차이점을 두어 각각 따로 진행했다.

A. 8번째 실험 모델에서 추가로 250에폭을 더 학습시켜 총 500에폭만큼 학습된 모델로 만들기. (base_channels는 기본값)

B. 처음부터 다시 250에폭을 학습시키되 base_channels의 값, 즉 GAN의 파라미터 수를 2배인 256으로 하여 진행. 이 때 오류로 인해 학습률은 0.00002, 0.00001 등의 값 사용. 총 191에폭만큼 학습을 진행했다.

A실험은 이전의 8번째 실험에서 250에폭 내내 성능이 향상되는 모습이 보였다는 점에서 추가로 250에폭을 더 진행한 것이다. 역시 전보다 더 피아노의 소리에 가깝게 들렸지만 약간의 노이즈가 섞여서 들렸고 피아노 같지 않은 소리를 낼 때도 종종 있었다. 그리고 모델이 향상되는 속도가 점점 느려져 500에폭 이상은 추가로 진행해도 그리 큰 차이가 나지 않을 것이라 판단했다.

B실험은 파라미터가 2배인 만큼 학습에 들어가는 시간도 2배가 걸렸다. 그렇게 얻은 결과물은 피아노의 소리를 A실험보다도 잘 재현해냈으나 멜로디에 문제가 있었다. 4번째 실험에서는 너무 단조로운 멜로디만 나와 문제였다면 이번에는 거의 난타에 가까운 혼란스러운 음악을 만들어서 문제였다. 데이터셋 일부에 아주 빠른 곡이 포함되어 있었는데 이것의 영향으로 인해 발생한 듯하다.

번외로 B 실험 모델에 모차르트의 곡만 10에폭 파인튜닝해보았는데 (파라미터 256개) 음질은 떨어지지만 피아노의 음색으로 모차르트의 느낌이 약간 나는 결과물을 얻을 수 있었다. 음질 문제는 아마 파인튜닝 학습량이 적어서 그런 것으로 보이는데 이 정도로 난타 뿐이었던 원래의 모델에서 음악적 구성을 모차르트 풍으로 바꿀 수 있었으므로 이 방법은 꽤나 유효한 것으로 보인다.

이 실험을 통해 같은 시간 동안 2배의 에폭을 학습하는 것보다 파라미터를 2배로 늘리는 것이 훨씬 효율적이라는 사실을 알 수 있었다.

### 열 한 번째 실험

이번 실험에서는 파인튜닝 없이 비슷한 특징을 갖는 피아노 곡으로만 구성된 데이터셋을 사용하여 256의 base channels로 250에폭 학습시켰다. (학습률 0.00002)

서로 다른 데이터셋으로 나누어 2개의 모델로 따로 훈련이 진행되었다. 이 때 사용된 데이터셋은 다음과 같다.

* 게임 ost 피아노 연주곡 (파이널 판타지) (24시간 분량)

* 클래식 피아노 연주곡 (모차르트) ( 10시간 분량)

사전 학습 및 파인튜닝이 아니기 때문에 다양한 피아노 음악을 만들기에는 비교적 한계가 뚜렷할 것으로 예상된다. 그러나 그만큼 특정한 음악을 생성하는 데에 특화되어 더 나은 음질과 음색으로 원하는 곡을 만들어내지 않을까 기대했다.

하지만 결과를 보니 생각보다 음질, 음색, 음악적 특징에서 아쉬운 점을 보였다. 그나마 게임 ost 모델은 음악적인 수준이 조금 괜찮은 모습을 보여주었지만 모차르트의 곡으로 학습한 모델은 너무 불안정한 모습을 보였다.

이 문제는 데이터셋의 크기 차이도 있지만 아무래도 노트 밀도가 영향을 준 것으로 보인다. 모차르트 음악이 같은 시간 동안 건반을 더 많이 치므로 모델이 학습하는 데에 더 어려움을 겪었을 것이다.

만약 100에폭 정도를 추가로 학습시킨다면 둘 다 더 나은 모습을 보여줄 것으로 예상된다. 하지만 음색과 음질 부분은 분명한 향상이 예상되는 반면 음악적인 부분까지 개선될지는 알 수 없다.

### 열 두 번째 실험

지금까지의 실험을 기반으로 최종적인 실험에 돌입했다.

우선 피아노 midi 데이터셋을 256의 base channels로 283에폭 학습시켰다. (학습률 0.00002) 이를 통해 피아노 소리를 훌륭하게 재현해내는 사전학습 모델을 만들었다.

이 모델은 음악적 측면에서는 아직 단순하게 느껴졌지만 괜찮게 들렸다. 사용한 데이터셋의 특징을 매우 잘 학습하여 좋은 코드진행을 보여주었으며 이로 인해 base channels = 128일 때보다 사람이 듣기에 화음이 잘 맞게 느껴졌다. 그 뿐 아니라 피아노 소리도 더 풍부한 음색으로 들렸다.

이렇게 만들어진 모델에 다시 모차르트의 곡만을 모아둔 데이터셋으로 파인튜닝해보았다.

바로 이전의 실험과는 달리 음악적으로 괜찮은 모습을 보여주었다. 사전학습모델에 비해서는 음질과 음색이 약간 떨어졌지만 모차르트 풍의 음악을 충분히 보여주었으며 불안정한 모습도 보이지 않았다.

파인튜닝은 100에폭 진행되었는데 만약 추가로 학습을 진행했다면 음색이 개선되었을 수 있다. 그러나 과적합의 문제가 발생할 수 있기 때문에 여기서 마무리하기로 했다. 모차르트 데이터셋의 크기가 비교적 작은 편이기 때문에 만약 너무 많은 학습을 하면 독창성을 잃어버릴 수 있기 때문이다.